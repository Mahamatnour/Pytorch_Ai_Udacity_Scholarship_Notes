

# Lessons 2

Introduction To Neural Network 

## 1- Introduction 

## 2- Classification Problem 1



## 3- Classification Problem 1 

## 4- Linear Boundaries 

wx1 + wx2 + b = 0

Wx + b = 0

w = (w1, w2)

x = (x1, x2)

y= label 0 or 1

y = 

## 5- Highest Dimensions 

## 6- Perceptrons 

## 7- Why Neural Networks?

## 8- Perceptrons as Logical Operators 

- And Perceptrons 

![and-quiz](/Users/mahamatnouralimai/Desktop/1-2018:2019/pytorch_udacity_scholarship_learning_notes/Notes/and-quiz.png)

- And Perceptrons 

![xor](/Users/mahamatnouralimai/Desktop/1-2018:2019/pytorch_udacity_scholarship_learning_notes/Notes/xor.png)

![and-to-or](/Users/mahamatnouralimai/Desktop/1-2018:2019/pytorch_udacity_scholarship_learning_notes/Notes/and-to-or.png)



![xor-quiz](/Users/mahamatnouralimai/Desktop/1-2018:2019/pytorch_udacity_scholarship_learning_notes/Notes/xor-quiz.png)



## 9- Perceptron Trick 

## 10- Perceptrons Algorithm 

## 11- Non-Linear Regions 

## 12- Error Functions 

## 13- Log-loss Error Functions 

## 14- Discrete vs Continous 

## 15- Softmax 

## 16- One- Hot Encoding 

## 17- Maximum Likelihood

